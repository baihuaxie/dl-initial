----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 24, 32, 32]             648
       BatchNorm2d-2           [-1, 24, 32, 32]              48
              ReLU-3           [-1, 24, 32, 32]               0
       BatchNorm2d-4           [-1, 24, 32, 32]              48
              ReLU-5           [-1, 24, 32, 32]               0
            Conv2d-6           [-1, 12, 32, 32]           2,592
        DenseLayer-7           [-1, 12, 32, 32]               0
       BatchNorm2d-8           [-1, 36, 32, 32]              72
              ReLU-9           [-1, 36, 32, 32]               0
           Conv2d-10           [-1, 12, 32, 32]           3,888
       DenseLayer-11           [-1, 12, 32, 32]               0
      BatchNorm2d-12           [-1, 48, 32, 32]              96
             ReLU-13           [-1, 48, 32, 32]               0
           Conv2d-14           [-1, 12, 32, 32]           5,184
       DenseLayer-15           [-1, 12, 32, 32]               0
      BatchNorm2d-16           [-1, 60, 32, 32]             120
             ReLU-17           [-1, 60, 32, 32]               0
           Conv2d-18           [-1, 12, 32, 32]           6,480
       DenseLayer-19           [-1, 12, 32, 32]               0
      BatchNorm2d-20           [-1, 72, 32, 32]             144
             ReLU-21           [-1, 72, 32, 32]               0
           Conv2d-22           [-1, 12, 32, 32]           7,776
       DenseLayer-23           [-1, 12, 32, 32]               0
      BatchNorm2d-24           [-1, 84, 32, 32]             168
             ReLU-25           [-1, 84, 32, 32]               0
           Conv2d-26           [-1, 12, 32, 32]           9,072
       DenseLayer-27           [-1, 12, 32, 32]               0
      BatchNorm2d-28           [-1, 96, 32, 32]             192
             ReLU-29           [-1, 96, 32, 32]               0
           Conv2d-30           [-1, 12, 32, 32]          10,368
       DenseLayer-31           [-1, 12, 32, 32]               0
      BatchNorm2d-32          [-1, 108, 32, 32]             216
             ReLU-33          [-1, 108, 32, 32]               0
           Conv2d-34           [-1, 12, 32, 32]          11,664
       DenseLayer-35           [-1, 12, 32, 32]               0
      BatchNorm2d-36          [-1, 120, 32, 32]             240
             ReLU-37          [-1, 120, 32, 32]               0
           Conv2d-38           [-1, 12, 32, 32]          12,960
       DenseLayer-39           [-1, 12, 32, 32]               0
      BatchNorm2d-40          [-1, 132, 32, 32]             264
             ReLU-41          [-1, 132, 32, 32]               0
           Conv2d-42           [-1, 12, 32, 32]          14,256
       DenseLayer-43           [-1, 12, 32, 32]               0
      BatchNorm2d-44          [-1, 144, 32, 32]             288
             ReLU-45          [-1, 144, 32, 32]               0
           Conv2d-46           [-1, 12, 32, 32]          15,552
       DenseLayer-47           [-1, 12, 32, 32]               0
      BatchNorm2d-48          [-1, 156, 32, 32]             312
             ReLU-49          [-1, 156, 32, 32]               0
           Conv2d-50           [-1, 12, 32, 32]          16,848
       DenseLayer-51           [-1, 12, 32, 32]               0
          Dropout-52          [-1, 168, 32, 32]               0
           Conv2d-53          [-1, 168, 32, 32]          28,224
        AvgPool2d-54          [-1, 168, 17, 17]               0
  TransitionLayer-55          [-1, 168, 17, 17]               0
          Dropout-56          [-1, 168, 17, 17]               0
      BatchNorm2d-57          [-1, 168, 17, 17]             336
             ReLU-58          [-1, 168, 17, 17]               0
           Conv2d-59           [-1, 12, 17, 17]          18,144
       DenseLayer-60           [-1, 12, 17, 17]               0
      BatchNorm2d-61          [-1, 180, 17, 17]             360
             ReLU-62          [-1, 180, 17, 17]               0
           Conv2d-63           [-1, 12, 17, 17]          19,440
       DenseLayer-64           [-1, 12, 17, 17]               0
      BatchNorm2d-65          [-1, 192, 17, 17]             384
             ReLU-66          [-1, 192, 17, 17]               0
           Conv2d-67           [-1, 12, 17, 17]          20,736
       DenseLayer-68           [-1, 12, 17, 17]               0
      BatchNorm2d-69          [-1, 204, 17, 17]             408
             ReLU-70          [-1, 204, 17, 17]               0
           Conv2d-71           [-1, 12, 17, 17]          22,032
       DenseLayer-72           [-1, 12, 17, 17]               0
      BatchNorm2d-73          [-1, 216, 17, 17]             432
             ReLU-74          [-1, 216, 17, 17]               0
           Conv2d-75           [-1, 12, 17, 17]          23,328
       DenseLayer-76           [-1, 12, 17, 17]               0
      BatchNorm2d-77          [-1, 228, 17, 17]             456
             ReLU-78          [-1, 228, 17, 17]               0
           Conv2d-79           [-1, 12, 17, 17]          24,624
       DenseLayer-80           [-1, 12, 17, 17]               0
      BatchNorm2d-81          [-1, 240, 17, 17]             480
             ReLU-82          [-1, 240, 17, 17]               0
           Conv2d-83           [-1, 12, 17, 17]          25,920
       DenseLayer-84           [-1, 12, 17, 17]               0
      BatchNorm2d-85          [-1, 252, 17, 17]             504
             ReLU-86          [-1, 252, 17, 17]               0
           Conv2d-87           [-1, 12, 17, 17]          27,216
       DenseLayer-88           [-1, 12, 17, 17]               0
      BatchNorm2d-89          [-1, 264, 17, 17]             528
             ReLU-90          [-1, 264, 17, 17]               0
           Conv2d-91           [-1, 12, 17, 17]          28,512
       DenseLayer-92           [-1, 12, 17, 17]               0
      BatchNorm2d-93          [-1, 276, 17, 17]             552
             ReLU-94          [-1, 276, 17, 17]               0
           Conv2d-95           [-1, 12, 17, 17]          29,808
       DenseLayer-96           [-1, 12, 17, 17]               0
      BatchNorm2d-97          [-1, 288, 17, 17]             576
             ReLU-98          [-1, 288, 17, 17]               0
           Conv2d-99           [-1, 12, 17, 17]          31,104
      DenseLayer-100           [-1, 12, 17, 17]               0
     BatchNorm2d-101          [-1, 300, 17, 17]             600
            ReLU-102          [-1, 300, 17, 17]               0
          Conv2d-103           [-1, 12, 17, 17]          32,400
      DenseLayer-104           [-1, 12, 17, 17]               0
         Dropout-105          [-1, 312, 17, 17]               0
          Conv2d-106          [-1, 312, 17, 17]          97,344
       AvgPool2d-107            [-1, 312, 9, 9]               0
 TransitionLayer-108            [-1, 312, 9, 9]               0
         Dropout-109            [-1, 312, 9, 9]               0
     BatchNorm2d-110            [-1, 312, 9, 9]             624
            ReLU-111            [-1, 312, 9, 9]               0
          Conv2d-112             [-1, 12, 9, 9]          33,696
      DenseLayer-113             [-1, 12, 9, 9]               0
     BatchNorm2d-114            [-1, 324, 9, 9]             648
            ReLU-115            [-1, 324, 9, 9]               0
          Conv2d-116             [-1, 12, 9, 9]          34,992
      DenseLayer-117             [-1, 12, 9, 9]               0
     BatchNorm2d-118            [-1, 336, 9, 9]             672
            ReLU-119            [-1, 336, 9, 9]               0
          Conv2d-120             [-1, 12, 9, 9]          36,288
      DenseLayer-121             [-1, 12, 9, 9]               0
     BatchNorm2d-122            [-1, 348, 9, 9]             696
            ReLU-123            [-1, 348, 9, 9]               0
          Conv2d-124             [-1, 12, 9, 9]          37,584
      DenseLayer-125             [-1, 12, 9, 9]               0
     BatchNorm2d-126            [-1, 360, 9, 9]             720
            ReLU-127            [-1, 360, 9, 9]               0
          Conv2d-128             [-1, 12, 9, 9]          38,880
      DenseLayer-129             [-1, 12, 9, 9]               0
     BatchNorm2d-130            [-1, 372, 9, 9]             744
            ReLU-131            [-1, 372, 9, 9]               0
          Conv2d-132             [-1, 12, 9, 9]          40,176
      DenseLayer-133             [-1, 12, 9, 9]               0
     BatchNorm2d-134            [-1, 384, 9, 9]             768
            ReLU-135            [-1, 384, 9, 9]               0
          Conv2d-136             [-1, 12, 9, 9]          41,472
      DenseLayer-137             [-1, 12, 9, 9]               0
     BatchNorm2d-138            [-1, 396, 9, 9]             792
            ReLU-139            [-1, 396, 9, 9]               0
          Conv2d-140             [-1, 12, 9, 9]          42,768
      DenseLayer-141             [-1, 12, 9, 9]               0
     BatchNorm2d-142            [-1, 408, 9, 9]             816
            ReLU-143            [-1, 408, 9, 9]               0
          Conv2d-144             [-1, 12, 9, 9]          44,064
      DenseLayer-145             [-1, 12, 9, 9]               0
     BatchNorm2d-146            [-1, 420, 9, 9]             840
            ReLU-147            [-1, 420, 9, 9]               0
          Conv2d-148             [-1, 12, 9, 9]          45,360
      DenseLayer-149             [-1, 12, 9, 9]               0
     BatchNorm2d-150            [-1, 432, 9, 9]             864
            ReLU-151            [-1, 432, 9, 9]               0
          Conv2d-152             [-1, 12, 9, 9]          46,656
      DenseLayer-153             [-1, 12, 9, 9]               0
     BatchNorm2d-154            [-1, 444, 9, 9]             888
            ReLU-155            [-1, 444, 9, 9]               0
          Conv2d-156             [-1, 12, 9, 9]          47,952
      DenseLayer-157             [-1, 12, 9, 9]               0
         Dropout-158            [-1, 456, 9, 9]               0
AdaptiveAvgPool2d-159            [-1, 456, 1, 1]               0
          Linear-160                   [-1, 10]           4,570
================================================================
Total params: 1,057,474
Trainable params: 1,057,474
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 44.47
Params size (MB): 4.03
Estimated Total Size (MB): 48.51
----------------------------------------------------------------
