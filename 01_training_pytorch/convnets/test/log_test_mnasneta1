----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
             ReLU6-3           [-1, 16, 32, 32]               0
           Dropout-4           [-1, 16, 32, 32]               0
            Conv2d-5           [-1, 16, 32, 32]             144
       BatchNorm2d-6           [-1, 16, 32, 32]              32
              ReLU-7           [-1, 16, 32, 32]               0
           Dropout-8           [-1, 16, 32, 32]               0
            Conv2d-9           [-1, 16, 32, 32]             256
      BatchNorm2d-10           [-1, 16, 32, 32]              32
        DWSepConv-11           [-1, 16, 32, 32]               0
           Conv2d-12           [-1, 24, 16, 16]             384
      BatchNorm2d-13           [-1, 24, 16, 16]              48
           Conv2d-14           [-1, 96, 32, 32]           1,536
      BatchNorm2d-15           [-1, 96, 32, 32]             192
            ReLU6-16           [-1, 96, 32, 32]               0
          Dropout-17           [-1, 96, 32, 32]               0
           Conv2d-18           [-1, 96, 16, 16]             864
      BatchNorm2d-19           [-1, 96, 16, 16]             192
            ReLU6-20           [-1, 96, 16, 16]               0
          Dropout-21           [-1, 96, 16, 16]               0
           Conv2d-22           [-1, 24, 16, 16]           2,304
      BatchNorm2d-23           [-1, 24, 16, 16]              48
          Dropout-24           [-1, 24, 16, 16]               0
           MBConv-25           [-1, 24, 16, 16]               0
           Conv2d-26          [-1, 144, 16, 16]           3,456
      BatchNorm2d-27          [-1, 144, 16, 16]             288
            ReLU6-28          [-1, 144, 16, 16]               0
          Dropout-29          [-1, 144, 16, 16]               0
           Conv2d-30          [-1, 144, 16, 16]           1,296
      BatchNorm2d-31          [-1, 144, 16, 16]             288
            ReLU6-32          [-1, 144, 16, 16]               0
          Dropout-33          [-1, 144, 16, 16]               0
           Conv2d-34           [-1, 24, 16, 16]           3,456
      BatchNorm2d-35           [-1, 24, 16, 16]              48
          Dropout-36           [-1, 24, 16, 16]               0
           MBConv-37           [-1, 24, 16, 16]               0
           Conv2d-38             [-1, 40, 8, 8]             960
      BatchNorm2d-39             [-1, 40, 8, 8]              80
           Conv2d-40           [-1, 72, 16, 16]           1,728
      BatchNorm2d-41           [-1, 72, 16, 16]             144
            ReLU6-42           [-1, 72, 16, 16]               0
          Dropout-43           [-1, 72, 16, 16]               0
           Conv2d-44             [-1, 72, 8, 8]           1,800
      BatchNorm2d-45             [-1, 72, 8, 8]             144
            ReLU6-46             [-1, 72, 8, 8]               0
          Dropout-47             [-1, 72, 8, 8]               0
AdaptiveAvgPool2d-48             [-1, 72, 1, 1]               0
           Linear-49                    [-1, 9]             657
             ReLU-50                    [-1, 9]               0
           Linear-51                   [-1, 72]             720
          Sigmoid-52                   [-1, 72]               0
            SEopt-53             [-1, 72, 8, 8]               0
           Conv2d-54             [-1, 40, 8, 8]           2,880
      BatchNorm2d-55             [-1, 40, 8, 8]              80
          Dropout-56             [-1, 40, 8, 8]               0
           MBConv-57             [-1, 40, 8, 8]               0
           Conv2d-58            [-1, 120, 8, 8]           4,800
      BatchNorm2d-59            [-1, 120, 8, 8]             240
            ReLU6-60            [-1, 120, 8, 8]               0
          Dropout-61            [-1, 120, 8, 8]               0
           Conv2d-62            [-1, 120, 8, 8]           3,000
      BatchNorm2d-63            [-1, 120, 8, 8]             240
            ReLU6-64            [-1, 120, 8, 8]               0
          Dropout-65            [-1, 120, 8, 8]               0
AdaptiveAvgPool2d-66            [-1, 120, 1, 1]               0
           Linear-67                   [-1, 15]           1,815
             ReLU-68                   [-1, 15]               0
           Linear-69                  [-1, 120]           1,920
          Sigmoid-70                  [-1, 120]               0
            SEopt-71            [-1, 120, 8, 8]               0
           Conv2d-72             [-1, 40, 8, 8]           4,800
      BatchNorm2d-73             [-1, 40, 8, 8]              80
          Dropout-74             [-1, 40, 8, 8]               0
           MBConv-75             [-1, 40, 8, 8]               0
           Conv2d-76            [-1, 120, 8, 8]           4,800
      BatchNorm2d-77            [-1, 120, 8, 8]             240
            ReLU6-78            [-1, 120, 8, 8]               0
          Dropout-79            [-1, 120, 8, 8]               0
           Conv2d-80            [-1, 120, 8, 8]           3,000
      BatchNorm2d-81            [-1, 120, 8, 8]             240
            ReLU6-82            [-1, 120, 8, 8]               0
          Dropout-83            [-1, 120, 8, 8]               0
AdaptiveAvgPool2d-84            [-1, 120, 1, 1]               0
           Linear-85                   [-1, 15]           1,815
             ReLU-86                   [-1, 15]               0
           Linear-87                  [-1, 120]           1,920
          Sigmoid-88                  [-1, 120]               0
            SEopt-89            [-1, 120, 8, 8]               0
           Conv2d-90             [-1, 40, 8, 8]           4,800
      BatchNorm2d-91             [-1, 40, 8, 8]              80
          Dropout-92             [-1, 40, 8, 8]               0
           MBConv-93             [-1, 40, 8, 8]               0
           Conv2d-94             [-1, 80, 8, 8]           3,200
      BatchNorm2d-95             [-1, 80, 8, 8]             160
           Conv2d-96            [-1, 240, 8, 8]           9,600
      BatchNorm2d-97            [-1, 240, 8, 8]             480
            ReLU6-98            [-1, 240, 8, 8]               0
          Dropout-99            [-1, 240, 8, 8]               0
          Conv2d-100            [-1, 240, 8, 8]           2,160
     BatchNorm2d-101            [-1, 240, 8, 8]             480
           ReLU6-102            [-1, 240, 8, 8]               0
         Dropout-103            [-1, 240, 8, 8]               0
          Conv2d-104             [-1, 80, 8, 8]          19,200
     BatchNorm2d-105             [-1, 80, 8, 8]             160
         Dropout-106             [-1, 80, 8, 8]               0
          MBConv-107             [-1, 80, 8, 8]               0
          Conv2d-108            [-1, 480, 8, 8]          38,400
     BatchNorm2d-109            [-1, 480, 8, 8]             960
           ReLU6-110            [-1, 480, 8, 8]               0
         Dropout-111            [-1, 480, 8, 8]               0
          Conv2d-112            [-1, 480, 8, 8]           4,320
     BatchNorm2d-113            [-1, 480, 8, 8]             960
           ReLU6-114            [-1, 480, 8, 8]               0
         Dropout-115            [-1, 480, 8, 8]               0
          Conv2d-116             [-1, 80, 8, 8]          38,400
     BatchNorm2d-117             [-1, 80, 8, 8]             160
         Dropout-118             [-1, 80, 8, 8]               0
          MBConv-119             [-1, 80, 8, 8]               0
          Conv2d-120            [-1, 480, 8, 8]          38,400
     BatchNorm2d-121            [-1, 480, 8, 8]             960
           ReLU6-122            [-1, 480, 8, 8]               0
         Dropout-123            [-1, 480, 8, 8]               0
          Conv2d-124            [-1, 480, 8, 8]           4,320
     BatchNorm2d-125            [-1, 480, 8, 8]             960
           ReLU6-126            [-1, 480, 8, 8]               0
         Dropout-127            [-1, 480, 8, 8]               0
          Conv2d-128             [-1, 80, 8, 8]          38,400
     BatchNorm2d-129             [-1, 80, 8, 8]             160
         Dropout-130             [-1, 80, 8, 8]               0
          MBConv-131             [-1, 80, 8, 8]               0
          Conv2d-132            [-1, 480, 8, 8]          38,400
     BatchNorm2d-133            [-1, 480, 8, 8]             960
           ReLU6-134            [-1, 480, 8, 8]               0
         Dropout-135            [-1, 480, 8, 8]               0
          Conv2d-136            [-1, 480, 8, 8]           4,320
     BatchNorm2d-137            [-1, 480, 8, 8]             960
           ReLU6-138            [-1, 480, 8, 8]               0
         Dropout-139            [-1, 480, 8, 8]               0
          Conv2d-140             [-1, 80, 8, 8]          38,400
     BatchNorm2d-141             [-1, 80, 8, 8]             160
         Dropout-142             [-1, 80, 8, 8]               0
          MBConv-143             [-1, 80, 8, 8]               0
          Conv2d-144            [-1, 112, 8, 8]           8,960
     BatchNorm2d-145            [-1, 112, 8, 8]             224
          Conv2d-146            [-1, 480, 8, 8]          38,400
     BatchNorm2d-147            [-1, 480, 8, 8]             960
           ReLU6-148            [-1, 480, 8, 8]               0
         Dropout-149            [-1, 480, 8, 8]               0
          Conv2d-150            [-1, 480, 8, 8]           4,320
     BatchNorm2d-151            [-1, 480, 8, 8]             960
           ReLU6-152            [-1, 480, 8, 8]               0
         Dropout-153            [-1, 480, 8, 8]               0
AdaptiveAvgPool2d-154            [-1, 480, 1, 1]               0
          Linear-155                   [-1, 60]          28,860
            ReLU-156                   [-1, 60]               0
          Linear-157                  [-1, 480]          29,280
         Sigmoid-158                  [-1, 480]               0
           SEopt-159            [-1, 480, 8, 8]               0
          Conv2d-160            [-1, 112, 8, 8]          53,760
     BatchNorm2d-161            [-1, 112, 8, 8]             224
         Dropout-162            [-1, 112, 8, 8]               0
          MBConv-163            [-1, 112, 8, 8]               0
          Conv2d-164            [-1, 672, 8, 8]          75,264
     BatchNorm2d-165            [-1, 672, 8, 8]           1,344
           ReLU6-166            [-1, 672, 8, 8]               0
         Dropout-167            [-1, 672, 8, 8]               0
          Conv2d-168            [-1, 672, 8, 8]           6,048
     BatchNorm2d-169            [-1, 672, 8, 8]           1,344
           ReLU6-170            [-1, 672, 8, 8]               0
         Dropout-171            [-1, 672, 8, 8]               0
AdaptiveAvgPool2d-172            [-1, 672, 1, 1]               0
          Linear-173                   [-1, 84]          56,532
            ReLU-174                   [-1, 84]               0
          Linear-175                  [-1, 672]          57,120
         Sigmoid-176                  [-1, 672]               0
           SEopt-177            [-1, 672, 8, 8]               0
          Conv2d-178            [-1, 112, 8, 8]          75,264
     BatchNorm2d-179            [-1, 112, 8, 8]             224
         Dropout-180            [-1, 112, 8, 8]               0
          MBConv-181            [-1, 112, 8, 8]               0
          Conv2d-182            [-1, 160, 4, 4]          17,920
     BatchNorm2d-183            [-1, 160, 4, 4]             320
          Conv2d-184            [-1, 672, 8, 8]          75,264
     BatchNorm2d-185            [-1, 672, 8, 8]           1,344
           ReLU6-186            [-1, 672, 8, 8]               0
         Dropout-187            [-1, 672, 8, 8]               0
          Conv2d-188            [-1, 672, 4, 4]          16,800
     BatchNorm2d-189            [-1, 672, 4, 4]           1,344
           ReLU6-190            [-1, 672, 4, 4]               0
         Dropout-191            [-1, 672, 4, 4]               0
AdaptiveAvgPool2d-192            [-1, 672, 1, 1]               0
          Linear-193                   [-1, 84]          56,532
            ReLU-194                   [-1, 84]               0
          Linear-195                  [-1, 672]          57,120
         Sigmoid-196                  [-1, 672]               0
           SEopt-197            [-1, 672, 4, 4]               0
          Conv2d-198            [-1, 160, 4, 4]         107,520
     BatchNorm2d-199            [-1, 160, 4, 4]             320
         Dropout-200            [-1, 160, 4, 4]               0
          MBConv-201            [-1, 160, 4, 4]               0
          Conv2d-202            [-1, 960, 4, 4]         153,600
     BatchNorm2d-203            [-1, 960, 4, 4]           1,920
           ReLU6-204            [-1, 960, 4, 4]               0
         Dropout-205            [-1, 960, 4, 4]               0
          Conv2d-206            [-1, 960, 4, 4]          24,000
     BatchNorm2d-207            [-1, 960, 4, 4]           1,920
           ReLU6-208            [-1, 960, 4, 4]               0
         Dropout-209            [-1, 960, 4, 4]               0
AdaptiveAvgPool2d-210            [-1, 960, 1, 1]               0
          Linear-211                  [-1, 120]         115,320
            ReLU-212                  [-1, 120]               0
          Linear-213                  [-1, 960]         116,160
         Sigmoid-214                  [-1, 960]               0
           SEopt-215            [-1, 960, 4, 4]               0
          Conv2d-216            [-1, 160, 4, 4]         153,600
     BatchNorm2d-217            [-1, 160, 4, 4]             320
         Dropout-218            [-1, 160, 4, 4]               0
          MBConv-219            [-1, 160, 4, 4]               0
          Conv2d-220            [-1, 960, 4, 4]         153,600
     BatchNorm2d-221            [-1, 960, 4, 4]           1,920
           ReLU6-222            [-1, 960, 4, 4]               0
         Dropout-223            [-1, 960, 4, 4]               0
          Conv2d-224            [-1, 960, 4, 4]          24,000
     BatchNorm2d-225            [-1, 960, 4, 4]           1,920
           ReLU6-226            [-1, 960, 4, 4]               0
         Dropout-227            [-1, 960, 4, 4]               0
AdaptiveAvgPool2d-228            [-1, 960, 1, 1]               0
          Linear-229                  [-1, 120]         115,320
            ReLU-230                  [-1, 120]               0
          Linear-231                  [-1, 960]         116,160
         Sigmoid-232                  [-1, 960]               0
           SEopt-233            [-1, 960, 4, 4]               0
          Conv2d-234            [-1, 160, 4, 4]         153,600
     BatchNorm2d-235            [-1, 160, 4, 4]             320
         Dropout-236            [-1, 160, 4, 4]               0
          MBConv-237            [-1, 160, 4, 4]               0
          Conv2d-238            [-1, 320, 4, 4]          51,200
     BatchNorm2d-239            [-1, 320, 4, 4]             640
          Conv2d-240            [-1, 960, 4, 4]         153,600
     BatchNorm2d-241            [-1, 960, 4, 4]           1,920
           ReLU6-242            [-1, 960, 4, 4]               0
         Dropout-243            [-1, 960, 4, 4]               0
          Conv2d-244            [-1, 960, 4, 4]           8,640
     BatchNorm2d-245            [-1, 960, 4, 4]           1,920
           ReLU6-246            [-1, 960, 4, 4]               0
         Dropout-247            [-1, 960, 4, 4]               0
          Conv2d-248            [-1, 320, 4, 4]         307,200
     BatchNorm2d-249            [-1, 320, 4, 4]             640
         Dropout-250            [-1, 320, 4, 4]               0
          MBConv-251            [-1, 320, 4, 4]               0
AdaptiveAvgPool2d-252            [-1, 320, 1, 1]               0
          Linear-253                   [-1, 10]           3,210
================================================================
Total params: 2,779,573
Trainable params: 2,779,573
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 28.17
Params size (MB): 10.60
Estimated Total Size (MB): 38.78
----------------------------------------------------------------
