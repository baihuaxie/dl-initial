{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600405907361",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "source": [
    "### Sequence mask\n",
    "\n",
    "* works by setting X[i, valid_len[i]:, :, ...] = masked_value (e.g., 0) for tensor X\n",
    "\n",
    "e.g.: if X is two-dimensional tensor of setences\n",
    "\n",
    "![sequence mask illustraion](../../97_assets/images/03_transformers_attention_notes_fig1_sequence_mask_illustration.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sequence mask \"\"\"\n",
    "\n",
    "def sequence_mask(x, valid_len, value=0):\n",
    "    \"\"\"\n",
    "    Apply mask to a sequence\n",
    "\n",
    "    Args:\n",
    "        x: (torch.tensor) input tensor that represents a sequence data\n",
    "        valid_len: (torch.tensor; 1D) mask x[i, valid_len[i]:] to value\n",
    "        value: (torch.dtype) value to fill in masked entries; default=0\n",
    "\n",
    "    Return:\n",
    "        (torch.tensor) a tensor of same size as x with masked entries \n",
    "    \"\"\"\n",
    "    output = x.clone()\n",
    "    for idx, sequence in enumerate(output):\n",
    "        try:\n",
    "            sequence[int(valid_len[idx]):] = value\n",
    "        except IndexError:\n",
    "            print(\"valid_len length mismatch!\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" masked softmax \"\"\"\n",
    "\n",
    "def masked_softmax(x, valid_len):\n",
    "    \"\"\"\n",
    "    Masked softmax function\n",
    "\n",
    "    - applies mask to dim=-1 of input tensor before softmax\n",
    "    - i.e., set x[i, :, :, ..., len[i]] = value (very small negative s.t. exp(value)=0)\n",
    "\n",
    "    Args:\n",
    "        x: (torch.tensor) input tensor; only accepts 3D\n",
    "        valid_len: (torch.tensor) for the last dimension, any value in x outside corresponding valid_length would be masked as zero\n",
    "\n",
    "    Return:\n",
    "        (torch.tensor) as tensor of the same shape as x but each value is within range [0,1] & sums to 1\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    if valid_len is None:\n",
    "        return nn.functional.softmax(x, dim=-1)\n",
    "    else:\n",
    "        if x.dim() != 3:\n",
    "            raise TypeError(\"input {}-D tensor shape not supported!\".format(x.dim()))\n",
    "        shape = x.shape\n",
    "        if valid_len.dim() == 1:\n",
    "            # broadcasts valid_len[i] to all entries in dim=1\n",
    "            # by repeats=shape[1], this assumes x is a 3D tensor; if tensor is 4D, should do repeats=shape[1]*shape[2]\n",
    "            valid_len = torch.repeat_interleave(valid_len, repeats=shape[1], dim=0)\n",
    "        else:\n",
    "            valid_len = valid_len.reshape(-1)\n",
    "        \n",
    "        x = sequence_mask(x.reshape(-1, shape[-1]), valid_len, value=-1e6)\n",
    "        return nn.functional.softmax(x.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" dot-product attentIon \"\"\"\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    dot-product attention\n",
    "\n",
    "    - score(query, key) = dot-product(query, key)\n",
    "    - requires that dim_q = dim_k\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dropout=0, **kwargs):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "\n",
    "        Args:\n",
    "            dropout: (float) dropout rate, default=0 (no dropout)\n",
    "            **kwargs: pointer to additional arguments\n",
    "        \"\"\"\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, valid_len=None):\n",
    "        \"\"\"\n",
    "        forward method\n",
    "\n",
    "        Args:\n",
    "            query: (torch.tensor) [batch, #_query, d]; query input to the attention module\n",
    "            key: (torch.tensor) [batch, #_kv, d]; use query and key to compute attention weights with score function + softmax\n",
    "            value: (torch.tensor) [batch, #_kv, dim_v]; output is weighted sum of values\n",
    "            valid_len: (torch.tensor) attention mask length applied to softmax for weights; [batch] or [batch, xx](?)\n",
    "        \"\"\"\n",
    "        d = query.shape[-1]\n",
    "        # 1) use torch.bmm to compute dot-product between query and keys; need to transpose dim=1 and dim=2 in key tensor to match dimensions\n",
    "        scores = torch.bmm(query, key.transpose(1, 2))\n",
    "        # 2) Q: why apply dropout to masked softmax output? dropout is random for all entries right?\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
    "        # 3) use torch.bmm again to compute weighted average of values by attention_weights\n",
    "        # -- no need for additional transpose, as attention_weights = [batch, #_query, #_kv]\n",
    "        return torch.bmm(attention_weights, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "test dot-product attention module\n",
    "\"\"\"\n",
    "\n",
    "### ---- dot-product attention --- ###\n",
    "atten = DotProductAttention(dropout=0.5)\n",
    "atten.eval()\n",
    "# keys = [batch=2, #_kv=10, d=2]\n",
    "keys = torch.ones(2, 10, 2)\n",
    "# values = [batch=2, #kv_10, dim_v=4]\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "# query = [batch=2, #_query=1, d=2]\n",
    "query = torch.ones(2, 1, 2)\n",
    "# valid_len: for batch=0, mask=2:; for batch=1, mask=6:\n",
    "valid_len = torch.tensor([2, 6])\n",
    "# output = [batch=2, #_query, dim_v]\n",
    "out = atten(query, keys, values, valid_len)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}