{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on torch.tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Find the maximum values and corresponding indices along axis=dim in a tensor \"\"\"\n",
    "\n",
    "x = torch.empty(5,3)\n",
    "values, indices = torch.max(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" convert a tuple into torch.Size object \"\"\"\n",
    "import torch\n",
    "\n",
    "shape = (4, 5, 6)\n",
    "print(shape)\n",
    "shape = torch.Size(shape)\n",
    "print(shape)\n",
    "torch.Tensor(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" convert a torch.tensor or torch.Size object into a tuple \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.randn(5)\n",
    "tuple(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" reshape tensor \"\"\"\n",
    "x.reshape((1,) + tuple(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converting between tensors and ndarrays \"\"\"\n",
    "\n",
    "# convert a tensor to a ndarray\n",
    "x = torch.randn(5,3)\n",
    "y = x.numpy()\n",
    "\n",
    "# conver a ndarray to a tensor\n",
    "z = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" tensor slice while maintaining shape \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.randint(0, 10, (1, 5, 16))\n",
    "print(x)\n",
    "x[:,0:2,:]\n",
    "# note that x[:,0,:] will reduce dimension; must use slicing [i:j] notation rather than indexing [i] notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" change tensor data type \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randint(0, 10, (20,))\n",
    "print(x.dtype)\n",
    "x = x.float()\n",
    "print(x.dtype)\n",
    "x = x.double()\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_note_:\n",
    "* if x.requires_grad=True, can not call numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" use torch.tensor.item() to return single-element tensor as a python number \"\"\"\n",
    "\n",
    "x = torch.tensor([1.0])\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" return size of a tensor \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.randn(5,3)\n",
    "# return a torch.Size object of dimensions along each axis\n",
    "print(x.size())\n",
    "print(x.shape)\n",
    "# return number of axis\n",
    "print(x.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" sum along a tensor dimension \"\"\"\n",
    "\n",
    "x = torch.randn(5,3,4)\n",
    "print(x)\n",
    "torch.sum(x,dim=1,keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" detach() \"\"\"\n",
    "\n",
    "x = torch.randn(5, 3, requires_grad=True)\n",
    "print(x)\n",
    "y = torch.sum(x * 2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "\n",
    "# create z by detach() x from compute graph\n",
    "z = y.detach()\n",
    "print(y.requires_grad)          # x is un-modified\n",
    "print(z.requires_grad)          # z.requires_grad set to False\n",
    "\n",
    "# call backward() method on y, with requires_grad=True\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# z and y shares same storage, any change to z will update y\n",
    "print(y)\n",
    "print(z)\n",
    "z += 1\n",
    "print(z)\n",
    "print(y)                        # y is also updated to +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" apply element-wise transformations to tensor \"\"\"\n",
    "\n",
    "x = torch.randn(5, 3)\n",
    "print(x)\n",
    "\n",
    "# take exp\n",
    "x = torch.exp(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_note_:\n",
    "* Pytorch does not currently support custom element-wise lambda functions for tensor\n",
    "  * a solution maybe to convert to np.ndarrays first, or use a stack of built-in element-wise functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" conditional slicing \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.rand(32,10)                               # x: a 32x10 tensor (e.g., xent outputs where batch=32, num of classes = 10)\n",
    "labels = torch.randint(0,10,(32,))                  # labels: a 32x1 tensor of integers (e.g., each element is a correct label index)\n",
    "print(x)\n",
    "print(labels)\n",
    "\n",
    "# torch.max(tensor, dim) will return a tuple of two tensors (val_max, arg_max)\n",
    "max_val, indices = torch.max(x, dim=1)\n",
    "# tensor[condition] (for 1d tensor; for higher d, use slicing syntax like [:, condition]) slices the tensor if the condition is evaluated to be True element-wise\n",
    "torch.sum(max_val[indices == labels]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" masked slicing conditioned on another tensor \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.zeros(32,10)                               # x: a 32x10 tensor (e.g., xent outputs where batch=32, num of classes = 10)\n",
    "labels = torch.randint(0,10,(32,))                  # labels: a 32x1 tensor of integers (e.g., each element is a correct label index)\n",
    "\n",
    "# construct a 32x10 mask tensor obj, mask[i][j] = True if labels[i] == j -> use values in labels as indices\n",
    "# note that gather(), select() methods all broadcast indices along axis other than dim specified, so won't work here\n",
    "mask = torch.BoolTensor([[True if i == labels[j] else False for i in range(x.size()[1]) ] for j in range(x.size()[0])])\n",
    "torch.masked_select(x, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_note_:\n",
    "* mask must be torch.BoolTensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" check if two tensors are equal \"\"\"\n",
    "\n",
    "# torch.equal() returns True if all elements are equal\n",
    "x = torch.rand(3,3)\n",
    "y = torch.rand(3,3)\n",
    "\n",
    "# returns a final boolean with torch.equal()\n",
    "print(torch.equal(x,y))\n",
    "# returns a BoolTensor with torch.eq()\n",
    "print(torch.eq(x,y))\n",
    "# or\n",
    "print(torch.all(torch.eq(x,y)))\n",
    "\n",
    "z = x.clone()\n",
    "print(torch.equal(x,z))\n",
    "\n",
    "# to return True if no elements are equal, can do the following\n",
    "print((x != y).all())\n",
    "\n",
    "# to return True if at least some elements are not equal, can do the following\n",
    "print((x != y).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" return all zero elements' indices in a tensor \"\"\"\n",
    "\n",
    "x = torch.rand(3,3)\n",
    "y = torch.rand(3,3)\n",
    "y[:,2] = x[:,2]\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# return the non-zero element indices as a tuple\n",
    "tup = (x - y).nonzero(as_tuple=True)\n",
    "print(tup)\n",
    "# can directly use the returned tuple to access the tensor elements\n",
    "print(x[tup])\n",
    "\n",
    "# return the zero element indices as a tuple\n",
    "tup2 = ((x - y) == 0).nonzero(as_tuple=True)\n",
    "print(tup2)\n",
    "print(x[tup2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.stack() vs torch.cat()\n",
    "* stack() a list of tensors along a new axis, output tensor would have an additional axis than input tensors\n",
    "* cat() a list of tensors along an existing axis, output tensor has equal # of axes as input tensors\n",
    "* stack() = unsqueeze() + cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" torch.stack() + torch.transpose() + torch.flatten() \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "t = torch.rand(1, 9, 1, 1)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "lst = torch.split(t, 3, dim=1)\n",
    "print(lst)\n",
    "a = torch.cat(lst, dim=1)\n",
    "print('break')\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "x = torch.stack(lst, dim=1)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "y = torch.transpose(x, dim0=1, dim1=2)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "z = torch.flatten(y, start_dim=1, end_dim=2)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 10, (12,))\n",
    "print(x)\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "import numpy as np\n",
    "np.array_split(y, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(1,)\n",
    "x2 = torch.rand(1,)\n",
    "x3 = torch.rand(1,)\n",
    "lst = [x1, x2, x3]\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "torch.stack(lst, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" keep in mind the difference between tensor([1]), tensor(1), tensor(1.)\"\"\"\n",
    "\n",
    "x1 = torch.tensor([1,2,3])\n",
    "x2 = torch.tensor([1])\n",
    "x3 = torch.tensor(1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print(x2.dim())\n",
    "print(x3.dim())\n",
    "# float\n",
    "x4 = torch.tensor(1.)\n",
    "print(x4)\n",
    "print(x4.shape)\n",
    "x5 = torch.tensor(1)\n",
    "print(x5)\n",
    "print(x5.reshape((1,)))\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lst = [torch.tensor(1), torch.tensor(1), torch.tensor(1)]\n",
    "torch.cat(lst, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" element-wise tensor multiplication by broadcasting \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.randint(0, 10, (5, 3, 3))\n",
    "y = torch.randint(0, 10, (5, 1, 1))\n",
    "print(x)\n",
    "print(y)\n",
    "# can directly multiply two tensors, if one of the axes matches in dimensions\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "torch.repeat_interleave(x, repeat, dim)\n",
    "\n",
    "- repeats every entry in tensor x by number=repeat for that dimension\n",
    "- repeat must have the same size as input along dim\n",
    "- dim is optional; if not specified, repeat must be integer\n",
    "\"\"\"\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "\n",
    "# repeat all entries in all dimensions & return a flattened tensor\n",
    "x_1 = torch.repeat_interleave(x, 2)\n",
    "print(x_1)\n",
    "\n",
    "# repeat entry x[i] by repeat[i] along dim=0\n",
    "x_2 = torch.repeat_interleave(x, torch.tensor([1,2,3,4]), dim=0)\n",
    "print(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create a random tensors for specified shape \"\"\"\n",
    "\n",
    "# integers; each entry within range [0, 9]; shape = (2,2,4)\n",
    "x = torch.randint(0, 10 ,(2, 2, 4))\n",
    "\n",
    "# random floats of shape torch.tensor([5,3,4]) sampled from N(0, 1)\n",
    "y_n = torch.randn(5, 3, 4)\n",
    "# random floats sampled from [0, 1] uniformly\n",
    "y_p = torch.rand(5, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" return data type in tensor \"\"\"\n",
    "import torch\n",
    "x = torch.randn(5, 3)\n",
    "len(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "enumerate a tensor \n",
    "\n",
    "- equivalent to split a tensor along dim=0\n",
    "\"\"\"\n",
    "\n",
    "x = torch.randn(5, 3, 4)\n",
    "print(x)\n",
    "\n",
    "for count, matrix in enumerate(x):\n",
    "    print(count)\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.bmm(input1, input2)\n",
    "\n",
    "- batch matrix-matrix product\n",
    "- input1=bxnxm, input2=bxmxp; returns bxnxp\n",
    "\"\"\"\n",
    "\n",
    "torch.bmm(torch.ones(2, 1, 3), torch.ones(2, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.arange\n",
    "\n",
    "- generate a 1-D tensor of arithmetic sequence\n",
    "\n",
    "note:\n",
    "- start=0, step=1 as defaults, these two arguments are optional\n",
    "\"\"\"\n",
    "\n",
    "# start=1, end=10, step=2\n",
    "x = torch.arange(1, 10, 2)\n",
    "print(x)\n",
    "# start=1, end=10, step=1\n",
    "y = torch.arange(10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" product of all elements in tensor \"\"\"\n",
    "\n",
    "x = torch.randint(0, 10, (2, 2))\n",
    "print(x)\n",
    "print(torch.prod(x, dim=0))\n",
    "print(torch.prod(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" torch.repeat \"\"\"\n",
    "\n",
    "x = torch.randint(0, 10, (2, 2))\n",
    "print(x)\n",
    "x.repeat(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" torch.clamp clips all elements in input tensor by a range \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randint(0, 10, (3, 4, 5))\n",
    "print(x)\n",
    "y = torch.clamp(x, min=3, max=6)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "* convert from numpy.dtype to torch.dtype is problematic\n",
    "* see [this post](https://discuss.pytorch.org/t/converting-a-numpy-dtype-to-torch-dtype/52279)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" torch.tensor vs torch.from_numpy() \"\"\"\n",
    "\n",
    "# from_numpy() expects a np.ndarray, so can not work for scalars\n",
    "# otherwise two method yields identical tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" torch.BoolTensor requires a list to instantiate \"\"\"\n",
    "import torch\n",
    "\n",
    "x = torch.BoolTensor([True for _ in range(10)])\n",
    "print(x)\n",
    "\n",
    "y = torch.BoolTensor((3,))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" use einops \"\"\"\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "data, labels = batch\n",
    "print(data.shape)\n",
    "a = rearrange(data[0:1, :3], 'c h w -> h w c')\n",
    "print(a.shape)\n",
    "b = rearrange(a, 'h w c -> () c h w')\n",
    "print(b.shape)\n",
    "c = rearrange(b, 'b c h w -> b (c h w)')\n",
    "print(c.shape)\n",
    "d = rearrange(c, '() classes -> classes')\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" torch.unsqueeze() \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3,4])\n",
    "print(x.shape)\n",
    "x1 = x.unsqueeze(0)\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "x2 = x.unsqueeze(1)\n",
    "print(x2)\n",
    "print(x2.shape)\n",
    "x3 = x.unsqueeze(-1)\n",
    "print(x3)\n",
    "print(x3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" some special tensor methods \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.rand((2,2))\n",
    "print(x)\n",
    "\n",
    "### returns the sign of a tensor\n",
    "print(x.sign())\n",
    "### matrix transpose (dim <= 2)\n",
    "print(x.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0c04e14e757fcd5c931b20c230f107ce3be1b6ffeb36695f3d01a868d65a6b9cc",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}