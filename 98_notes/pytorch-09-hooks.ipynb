{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### PyTorch hooks\n",
    "* a mechanism to incorporate user-defined codes into PyTorch tensors or module instances in the computation graph where there is no explicit way to access them\n",
    "    * allows: 1) inspection; 2) alteration of nodes in the compute graph (tensors or modules) that are not otherwise accessible \n",
    "* see [this tutorial](https://www.youtube.com/watch?v=syLFCVYua6Q) for more details\n",
    "* a hook is a callable function object\n",
    "* a hook can be registered to a node in the compute graph by several methods:\n",
    "    * tensor hooks:\n",
    "        * .register_hook(callable)\n",
    "    * module hooks:\n",
    "        * 1) .register_forward_pre_hook(callable): apply the hook function before forward() pass\n",
    "        * 2) .register_forward_hook(callable): apply the hook function after forward() pass\n",
    "        * 3) .register_backward_hook(callable): apply the hook function after backward() pass\n",
    "            * note: the .register_backward_hook() utility seems to have some bugs in PyTorch, currently work-around is to use tensor hooks for this situation\n",
    "* two types of hooks:\n",
    "    * tensor hooks: e.g., for gradients in the backward graph\n",
    "    * module hooks: e.g., for each layer in a network instance\n",
    "    \n",
    "![compute graph](./assets/images/pytorch-09-hooks-compute-graph-illustration.png)\n",
    "\n",
    "* when register a hook to a node:\n",
    "    * in the forward graph, a pointer to the hook callable function is added to an ordered dictionary field in the node\n",
    "        * there can be multiple hooks registered to the same node; they would be called orderly\n",
    "    * in the backward graph, if the node is an intermediate node, there would add a pointer to the ordered dictionary in the forward node\n",
    "* the ordered dictionary has key:value pair that:\n",
    "    * key is a hook handler; it is also returned by the .register_hook() call\n",
    "    * value is the hook callable function\n",
    "* tesnor hooks: never use inplace operations (or any operation that alters the input) in a hook callable function\n",
    "    * this is because in the backward graph, the gradients where the hook is applied to are likely also passed on to other nodes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" register tensor hooks \"\"\"\n",
    "import torch\n",
    "\n",
    "# leaf node A\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "print(a)\n",
    "# leaf node B\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "print(b)\n",
    "# intermediate node C\n",
    "c = a * b\n",
    "print(c)\n",
    "# leaf node D\n",
    "d = torch.tensor(4.0, requires_grad=True)\n",
    "print(d)\n",
    "# intermediate node E\n",
    "e = c * d\n",
    "print(e)\n",
    "\n",
    "# hook function\n",
    "def c_hook(grad):\n",
    "    print(grad)\n",
    "    return grad + 2\n",
    "\n",
    "# register hooks to intermediate node C\n",
    "c.register_hook(c_hook)\n",
    "c.register_hook(lambda grad: print(grad))   # can use lambda functions\n",
    "c.retain_grad()     # retain_grad() is also registered as a hook function\n",
    "\n",
    "# register hooks to leaf node D\n",
    "d.register_hook(lambda grad: grad + 100)\n",
    "\n",
    "# register hooks to intermediate node E\n",
    "e.retain_grad()\n",
    "e.register_hook(lambda grad: grad * 2)\n",
    "\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}